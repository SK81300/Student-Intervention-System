{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('student-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
       "0  ...         no       no       4         3      4    1    1      3        6   \n",
       "1  ...        yes       no       5         3      3    1    1      3        4   \n",
       "2  ...        yes       no       4         3      2    2    3      3       10   \n",
       "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
       "4  ...         no       no       4         3      2    1    2      5        4   \n",
       "\n",
       "  passed  \n",
       "0     no  \n",
       "1     no  \n",
       "2    yes  \n",
       "3    yes  \n",
       "4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after running the above code we have found that the last column is the target column and we have to make the predictions on the passed column only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: Data Exploration\n",
    "Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, you will need to compute the following:\n",
    "- The total number of students, n_students.\n",
    "- The total number of features for each student, n_features.\n",
    "- The number of those students who passed, n_passed.\n",
    "- The number of those students who failed, n_failed.\n",
    "- The graduation rate of the class, grad_rate, in percent (%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of students in the dataset are: 395\n",
      "The total number of features in the dataset are: 30\n",
      "The total number of students who have passed in the dataset are: 265\n",
      "The total number of students who have failed in the dataset are: 130\n",
      "The graduation rate of the students in the dataset are:67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students=len(data)\n",
    "n_features=len(data.columns[0:-1])\n",
    "n_passed=len(data[data.passed=='yes'])\n",
    "n_failed=len(data[data.passed=='no'])\n",
    "grad_rate=float(n_passed)/n_students*100\n",
    "print(\"The total number of students in the dataset are:\",n_students)\n",
    "print(\"The total number of features in the dataset are:\",n_features)\n",
    "print(\"The total number of students who have passed in the dataset are:\",n_passed)\n",
    "print(\"The total number of students who have failed in the dataset are:\",n_failed)\n",
    "print(\"The graduation rate of the students in the dataset are:{:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed=pd.value_counts(data['passed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    265\n",
      "no     130\n",
      "Name: passed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify feature and target columns**\n",
    "\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "Run the code cell below to separate the student data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature columns are: ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "The target columns are: passed\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "0     no\n",
      "1     no\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "Name: passed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "features_columns=list(data.columns[0:-1])\n",
    "target_columns=data.columns[-1]\n",
    "print(\"The feature columns are:\",features_columns)\n",
    "print(\"\\nThe target columns are:\",target_columns)\n",
    "X_all=data[features_columns]\n",
    "y_all=data[target_columns]\n",
    "print(X_all.head())\n",
    "print(y_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print (\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation: Training and Testing Data Split**\n",
    "\n",
    "So far, we have converted all categorical features into numeric values. For the next step, we split the data (both features and corresponding labels) into training and test sets. In the following code cell below, you will need to implement the following:\n",
    "Randomly shuffle and split the data (X_all, y_all) into training and testing subsets.\n",
    "Use 300 training points (approximately 75%) and 95 testing points (approximately 25%).\n",
    "Set a random_state for the function(s) you use, if provided.\n",
    "Store the results in X_train, X_test, y_train, and y_test.\n",
    "In [5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any additional functionality you may need here\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: Set the number of training points\n",
    "num_train = 300\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = x_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "def shuffle_and_split_data(x_all, y_all):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x_all, y_all, test_size=0.2405, random_state = 42)\n",
    "    return xtrain, xtest, ytrain, ytest\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = shuffle_and_split_data(x_all, y_all)\n",
    "\n",
    "X_train = xtrain\n",
    "X_test = xtest\n",
    "y_train = ytrain\n",
    "y_test = ytest\n",
    "\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluating Models**\n",
    "\n",
    "In this section, you will choose 3 supervised learning models that are appropriate for this problem and available in scikit-learn. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to varying sizes of training data (100 data points, 200 data points, and 300 data points) and measure the F1 score. You will need to produce three tables (one for each model) that shows the training set size, training time, prediction time, F1 score on the training set, and F1 score on the testing set.\n",
    "The following supervised learning models are currently available in scikit-learn that you may choose from:\n",
    "Gaussian Naive Bayes (GaussianNB)\n",
    "Decision Trees\n",
    "Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "K-Nearest Neighbors (KNeighbors)\n",
    "Stochastic Gradient Descent (SGDC)\n",
    "Support Vector Machines (SVM)\n",
    "Logistic Regression\n",
    "\n",
    "**Question 2 - Model Application**\n",
    "List three supervised learning models that are appropriate for this problem. For each model chosen\n",
    "Describe one real-world application in industry where the model can be applied. (You may need to do a small bit of research for this — give references!)\n",
    "What are the strengths of the model; when does it perform well?\n",
    "What are the weaknesses of the model; when does it perform poorly?\n",
    "What makes this model a good candidate for the problem, given what you know about the data?\n",
    "Answer: The three supervised models that are appropriate for this problem are : -- Logistic Regression -- Support Vector Machines(SVM) -- Ensemble Methods(RandomForest)\n",
    "\n",
    "**1) Logistic Regression :**\n",
    "\n",
    "1.1) Logistic Regression can be used to predict for 'Credit Risk Analysis'. It can be used to predict for which party a person is going to vote for.It can even be used to predict wheter a student will get an admission to a college or not based on a number of criteria.\n",
    "(Sources:https://smartdrill.com/logistic-regression.html ,Quora, Google)\n",
    "\n",
    "1.2) Advantages of Logistic Regression :\n",
    "You can use more than one explanatory variable (dependent variable) and those can either be dichotomous, ordinal, or continuous.\n",
    "It helps to remove the 'confounding effect'.\n",
    "It does not need a linear relationship between the dependent and independent variables. Logistic regression can handle all sorts of relationships, because it applies a non-linear log transformation to the predicted odds ratio.\n",
    "The independent variables do not need to be metric (interval or ratio scaled).\n",
    "Logistic Regression performs well when features are roughly linear and the problem is likely to be linearly separable\n",
    "\n",
    "1.3) Disadvantages of Logistic Regression :\n",
    "Binary logistic regression requires the dependent variable to be binary and ordinal logistic regression requires the dependent variable to be ordinal.\n",
    "Linearity test is required on a non-binomial dependent variable before including it in the model.\n",
    "It combines both binomial and normal distribution which can cause problems sometimes.\n",
    "Logistic Regression performs poorly if the features are highly correlated.\n",
    "\n",
    "1.4) Logistic Regression can be applied to our data as it can be seen thet the features are not so highly correlated. Also, the outcome is a binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>activities_no</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_no</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_no</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_no</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_no</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.163658</td>\n",
       "      <td>-0.163438</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>0.243665</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>0.126964</td>\n",
       "      <td>0.131125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>-0.103063</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>-0.086632</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>-0.209081</td>\n",
       "      <td>0.112094</td>\n",
       "      <td>-0.112094</td>\n",
       "      <td>-0.164669</td>\n",
       "      <td>0.164669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>-0.163658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623455</td>\n",
       "      <td>-0.171639</td>\n",
       "      <td>0.064944</td>\n",
       "      <td>-0.236680</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>0.030891</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108277</td>\n",
       "      <td>0.108277</td>\n",
       "      <td>-0.193263</td>\n",
       "      <td>0.193263</td>\n",
       "      <td>-0.168845</td>\n",
       "      <td>0.168845</td>\n",
       "      <td>-0.201463</td>\n",
       "      <td>0.201463</td>\n",
       "      <td>-0.039681</td>\n",
       "      <td>0.039681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>-0.163438</td>\n",
       "      <td>0.623455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.158194</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>-0.250408</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>-0.012846</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112643</td>\n",
       "      <td>0.112643</td>\n",
       "      <td>-0.157177</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>-0.174566</td>\n",
       "      <td>0.174566</td>\n",
       "      <td>-0.127507</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>-0.015602</td>\n",
       "      <td>0.015602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime</th>\n",
       "      <td>0.070641</td>\n",
       "      <td>-0.171639</td>\n",
       "      <td>-0.158194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100909</td>\n",
       "      <td>0.092239</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>0.083508</td>\n",
       "      <td>-0.083508</td>\n",
       "      <td>0.111302</td>\n",
       "      <td>-0.111302</td>\n",
       "      <td>-0.021962</td>\n",
       "      <td>0.021962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>-0.004140</td>\n",
       "      <td>0.064944</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>-0.100909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.173563</td>\n",
       "      <td>0.039731</td>\n",
       "      <td>-0.143198</td>\n",
       "      <td>-0.063904</td>\n",
       "      <td>-0.196019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089877</td>\n",
       "      <td>0.089877</td>\n",
       "      <td>-0.081325</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>-0.175081</td>\n",
       "      <td>0.175081</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.059422</td>\n",
       "      <td>-0.053285</td>\n",
       "      <td>0.053285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age      Medu      Fedu  traveltime  studytime  failures  \\\n",
       "age         1.000000 -0.163658 -0.163438    0.070641  -0.004140  0.243665   \n",
       "Medu       -0.163658  1.000000  0.623455   -0.171639   0.064944 -0.236680   \n",
       "Fedu       -0.163438  0.623455  1.000000   -0.158194  -0.009175 -0.250408   \n",
       "traveltime  0.070641 -0.171639 -0.158194    1.000000  -0.100909  0.092239   \n",
       "studytime  -0.004140  0.064944 -0.009175   -0.100909   1.000000 -0.173563   \n",
       "\n",
       "              famrel  freetime     goout      Dalc      ...       \\\n",
       "age         0.053940  0.016434  0.126964  0.131125      ...        \n",
       "Medu       -0.003914  0.030891  0.064094  0.019834      ...        \n",
       "Fedu       -0.001370 -0.012846  0.043105  0.002386      ...        \n",
       "traveltime -0.016808 -0.017025  0.028540  0.138325      ...        \n",
       "studytime   0.039731 -0.143198 -0.063904 -0.196019      ...        \n",
       "\n",
       "            activities_no  activities_yes  nursery_no  nursery_yes  higher_no  \\\n",
       "age              0.103063       -0.103063    0.086632    -0.086632   0.209081   \n",
       "Medu            -0.108277        0.108277   -0.193263     0.193263  -0.168845   \n",
       "Fedu            -0.112643        0.112643   -0.157177     0.157177  -0.174566   \n",
       "traveltime       0.007766       -0.007766    0.033338    -0.033338   0.083508   \n",
       "studytime       -0.089877        0.089877   -0.081325     0.081325  -0.175081   \n",
       "\n",
       "            higher_yes  internet_no  internet_yes  romantic_no  romantic_yes  \n",
       "age          -0.209081     0.112094     -0.112094    -0.164669      0.164669  \n",
       "Medu          0.168845    -0.201463      0.201463    -0.039681      0.039681  \n",
       "Fedu          0.174566    -0.127507      0.127507    -0.015602      0.015602  \n",
       "traveltime   -0.083508     0.111302     -0.111302    -0.021962      0.021962  \n",
       "studytime     0.175081    -0.059422      0.059422    -0.053285      0.053285  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.corr().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Support Vector Machines(SVM) :**\n",
    "\n",
    "2.1) SVM is used in financial industries in financial time series forecasting. (Source : http://www.svms.org/finance/)\n",
    "\n",
    "2.2) Advantages of SVM:\n",
    "It is a great classsification algorithm that gives a better decision boundary, a boundary with a large margin. This can be seen in the fig. below. alt text\n",
    "SVM even works well to find a decision boundary if the data is not linearly separable(i.e. can't be fitted with a straight line). This is shown below. alt text SVM provides us the choice of choosing a non-linear kernel too\n",
    "Less Overfiting in nature.\n",
    "Robust to noise\n",
    "SVM performs well if there is a two-class problem with balanced data set with almost zero or little noise.\n",
    "It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient\n",
    "\n",
    "2.3) Disadvantages of SVM:\n",
    "SVMs do not perform well on highly skewed/imbalanced data sets. These are training data sets in which the number of samples that fall in one of the classes far outnumber those that are a member of the other class.\n",
    "SVMs are also not a good option specially if you have multiple classes. alt text\n",
    "SVM is not good for incremental learning\n",
    "SVM is not desirable for very large datasets. Also, it performs very poorly if the number of features are greater in number than the number of training examples.\n",
    "\n",
    "2.4) SVM is well suited for our dataset because there are only two classes of outcome. Also, the number of features are not so large as well as the training set is relatively small, hence SVM is a good choice.\n",
    "**3) Ensemble Methods (Random Forest)**\n",
    "\n",
    "3.1) Application in industry : Random Forest algorithm is widely used in finance as well as in Machine Fault diagnosis (source: http://link.springer.com/chapter/10.1007%2F978-1-84628-814-2_82 , http://www.scientific.net/AMM.740.947)\n",
    "\n",
    "3.2) Advantages of Ensembles(Random Forest) :\n",
    "They do not expect linear features or even features that interact linearly.\n",
    "These algorithms handle very well high dimensional spaces as well as large number of training examples.\n",
    "RF generates an internal unbiased estimate of the generalization error as the forest building progresses.\n",
    "RF has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing.\n",
    "Random Forests attempts to mitigate the problems of high variance and high bias by averaging to find a natural balance between the two extremes.\n",
    "alt text\n",
    "RF perfroms well if the datset is class-balanced i.e.no class contains significantly more samples than the other.\n",
    "\n",
    "3.3) Disadvantages of Ensembles(Random Forest):\n",
    "RF are prone to 'Overfiting' if the dataset is noisy\n",
    "As the dataset grows, large number of trees are required, hence complexity of the model increases.\n",
    "For data including categorical variables with different number of levels, random forests are biased in favor of those attributes with more levels. Therefore, the variable importance scores from random forest are not reliable for this type of data.\n",
    "RF performs poorly when the number of dimensions is tooo high as compared to the number of training examples. Also, it is not the best suited algorihm when dataset contain categorical features at different levels as it will overfit in this case.\n",
    "\n",
    "*Setup*\n",
    "Run the code cell below to initialize three helper functions which you can use for training and testing the three supervised learning models you've chosen above. The functions are as follows:\n",
    "train_classifier - takes as input a classifier and training data and fits the classifier to the data.\n",
    "predict_labels - takes as input a fit classifier, features, and a target labeling and makes predictions using the F1 score.\n",
    "train_predict - takes as input a classifier, and the training and testing data, and performs train_clasifier and predict_labels.\n",
    "This function will report the F1 score for both the training and testing data separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print (\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trianing size 100 --\n",
      "Training a LogisticRegression using a training set size of 100. . .\n",
      "Trained model in 0.0020 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score for training set: 0.8613.\n",
      "Made predictions in 0.0060 seconds.\n",
      "F1 score for test set: 0.7704.\n",
      "Training a SVC using a training set size of 100. . .\n",
      "Trained model in 0.0030 seconds\n",
      "Made predictions in 0.0070 seconds.\n",
      "F1 score for training set: 0.8696.\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for test set: 0.7746.\n",
      "Training a RandomForestClassifier using a training set size of 100. . .\n",
      "Trained model in 0.2300 seconds\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for training set: 0.9844.\n",
      "Made predictions in 0.0030 seconds.\n",
      "F1 score for test set: 0.7317.\n",
      " \n",
      "--- Training size 200 ---\n",
      "Training a LogisticRegression using a training set size of 200. . .\n",
      "Trained model in 0.0030 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score for training set: 0.8523.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7914.\n",
      "Training a SVC using a training set size of 200. . .\n",
      "Trained model in 0.0050 seconds\n",
      "Made predictions in 0.0030 seconds.\n",
      "F1 score for training set: 0.8652.\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for test set: 0.7815.\n",
      "Training a RandomForestClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0180 seconds\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for training set: 0.9891.\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for test set: 0.7669.\n",
      " \n",
      "--- Training size 300 --\n",
      "Training a LogisticRegression using a training set size of 300. . .\n",
      "Trained model in 0.0030 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8430.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.8000.\n",
      "Training a SVC using a training set size of 300. . .\n",
      "Trained model in 0.0080 seconds\n",
      "Made predictions in 0.0070 seconds.\n",
      "F1 score for training set: 0.8686.\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for test set: 0.7785.\n",
      "Training a RandomForestClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0210 seconds\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for training set: 0.9927.\n",
      "Made predictions in 0.0020 seconds.\n",
      "F1 score for test set: 0.7344.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = LogisticRegression(random_state=42)\n",
    "clf_B = SVC(random_state=33)\n",
    "clf_C = RandomForestClassifier(random_state =42)\n",
    "\n",
    "# TODO: Set up the training set sizes\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "# TODO: Execute the 'train_predict' function for each classifier and each training set size\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "print('--- Trianing size 100 --')\n",
    "train_predict(clf_A, X_train_100, y_train_100, X_test, y_test)\n",
    "train_predict(clf_B, X_train_100, y_train_100, X_test, y_test)\n",
    "train_predict(clf_C, X_train_100, y_train_100, X_test, y_test)\n",
    "print (' ')\n",
    "\n",
    "print ('--- Training size 200 ---')\n",
    "train_predict(clf_A, X_train_200, y_train_200, X_test, y_test)\n",
    "train_predict(clf_B, X_train_200, y_train_200, X_test, y_test)\n",
    "train_predict(clf_C, X_train_200, y_train_200, X_test, y_test)\n",
    "print (' ')\n",
    "\n",
    "print ('--- Training size 300 --')\n",
    "train_predict(clf_A, X_train_300, y_train_300, X_test, y_test)\n",
    "train_predict(clf_B, X_train_300, y_train_300, X_test, y_test)\n",
    "train_predict(clf_C, X_train_300, y_train_300, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAACOCAYAAABZov05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDE0QBEHoEoihCYIgCF2C/w+kcENb0Rg1HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd73588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [100,200,300]\n",
    "y = [[0.6880, 0.7248, 0.6977],[0.7442, 0.7101, 0.6508 ],[0.7023, 0.7246, 0.6774]]\n",
    "plt.xlabel('No.of Training examples')\n",
    "plt.ylabel('F1 Score(Test)')\n",
    "plt.plot(x,y )\n",
    "plt.legend(['LR','SVM','RF'],loc=2,fontsize='small',fancybox=None, frameon=False)\n",
    "plt.tick_params(labelright=True)\n",
    "\n",
    "plt.subplot(212)\n",
    "y = [[0.1120, 0.0240, 0.0810],[0.0030, 0.0030, 0.0330],[0.0030, 0.0070, 0.0230]]\n",
    "plt.xlabel('No.of Training examples')\n",
    "plt.ylabel('Training time')\n",
    "plt.plot(x,y )\n",
    "plt.legend(['LR','SVM','RF'],loc=1,fontsize='small',fancybox=None, frameon=False)\n",
    "plt.tick_params(labelright=True)\n",
    "\n",
    "plt.subplots_adjust(hspace=50.0)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 - Choosing the Best Model**\n",
    "\n",
    "Based on the experiments you performed earlier, in one to two paragraphs, explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "\n",
    "*Answer*: \n",
    "The model selection is mainly dependent on two things :\n",
    "Training time : As we can see from the graph shown below, that RandomForest performs poorly in terms of training time. The performance of Logistic Regression as well as Support Vector Machines are very close . Hence we can infer that upto this point (not taking F1 score in consideration yet but talking in terms of cost), thatout of the three models, Logistic Regression or SVM should be considered for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEFCAYAAACl5zMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQlICCGEKf4fLRCg439xMLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd2c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x = [100,200,300]\n",
    "y = [[0.1120, 0.0240, 0.0810],[0.0030, 0.0030, 0.0330],[0.0030, 0.0070, 0.0230]]\n",
    "plt.xlabel('No.of Training examples')\n",
    "plt.ylabel('Training time')\n",
    "plt.plot(x,y )\n",
    "plt.legend(['LR','SVM','RF'],loc=1,fontsize='small',fancybox=None, frameon=False)\n",
    "plt.tick_params(labelright=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0030 seconds.\n",
      "Tuned model has a training F1 score of 0.8522.\n",
      "Made predictions in 0.0010 seconds.\n",
      "Tuned model has a testing F1 score of 0.8000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = {'C' : [0.01, 0.1, 1.0, 10, 100], 'kernel' : ['linear','rbf']}\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = SVC(random_state=42)\n",
    "\n",
    "# TODO: Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,pos_label='yes')\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf, param_grid = parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print (\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print (\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
